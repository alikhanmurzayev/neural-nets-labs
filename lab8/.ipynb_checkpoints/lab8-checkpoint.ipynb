{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 style=\"text-align: center;\"><b>На основе ШАД Яндекс</b></h3><h1 id=\"Домашнее-задание.-Обучение-нейронных-сетей-на-PyTorch.\">Домашнее задание. Обучение нейронных сетей на PyTorch.<a class=\"anchor-link\" href=\"#Домашнее-задание.-Обучение-нейронных-сетей-на-PyTorch.\">¶</a></h1><p>В этом домашнем задании вам предстоит предсказывать типы небесных объектов. Эту задачу вы будете решать с помощью нейронных сетей, используя библиотеку PyTorch.</p>\n",
    "<p>Вам необходимо заполнить пропуски в ноутбуке. Кое-где вас просят сделать выводы о проделанной работе. Постарайтесь ответить на вопросы обдуманно и развёрнуто.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 id=\"Дисклеймер-про-CrossEntropyLoss-и-NLLLoss\">Дисклеймер про CrossEntropyLoss и NLLLoss<a class=\"anchor-link\" href=\"#Дисклеймер-про-CrossEntropyLoss-и-NLLLoss\">¶</a></h1><p>Обычно в PyTorch не нужно делать Softmax как последний слой модели.</p>\n",
    "<ul>\n",
    "<li>Если Вы используете NLLLoss, то ему на вход надо давать лог вероятности, то есть выход слоя LogSoftmax. (Просто результат софтмакса, к которому применен логарифм)</li>\n",
    "<li>Если Вы используете CrossEntropyLoss, то применение LogSoftmax уже включено внутрь лосса, поэтому ему на вход надо подавать просто выход обычного линейного слоя без активации. По сути CrossEntropyLoss = LogSoftmax + NLLLoss</li>\n",
    "</ul>\n",
    "<p>Зачем такие сложности, чтобы посчитать обычную кросс энтропию? Дело в том, что нам в любом случае придется взять логарифм от результатов софтмакса, а если делать это одной функцией, то можно сделать более устойчивую реализацию, которая даст меньшую вычислительную погрешность.</p>\n",
    "<p>Таким образом, если у вас в конце сети, решающей задачу классификации, стоит просто линейный слой без активации, то вам нужно использовать CrossEntropy. В этой домашке везде используется лосс CrossEntropy</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 id=\"Задание-1.-Создайте-генератор-батчей.\">Задание 1. Создайте генератор батчей.<a class=\"anchor-link\" href=\"#Задание-1.-Создайте-генератор-батчей.\">¶</a></h1><p>В этот раз мы хотим сделать генератор, который будет максимально похож на то, что используется в реальном обучении.</p>\n",
    "<p>С помощью numpy вам нужно перемешать исходную выборку и выбирать из нее батчи размером batch_size, если размер выборки не делился на размер батча, то последний батч должен иметь размер меньше batch_size и состоять просто из всех оставшихся объектов. Возвращать нужно в формате (X_batch, y_batch). Необходимо написать именно генератор, то есть вместо return использовать yield.</p>\n",
    "<p>Хорошая статья про генераторы: <a href=\"https://habr.com/ru/post/132554/\">https://habr.com/ru/post/132554/</a></p>\n",
    "<p><strong>Ответ на задание - код</strong></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(X, y, batch_size):\n",
    "    np.random.seed(42)\n",
    "    perm = np.random.permutation(len(X))\n",
    "    \n",
    "    for start_index in range(0, len(perm), batch_size):\n",
    "        indices = perm[start_index:start_index+batch_size]\n",
    "        yield X[indices], y[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Попробуем потестировать наш код</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inspect import isgeneratorfunction\n",
    "assert isgeneratorfunction(batch_generator), \"batch_generator должен быть генератором! В условии есть ссылка на доки\"\n",
    "\n",
    "X = np.array([\n",
    "              [1, 2, 3],\n",
    "              [4, 5, 6],\n",
    "              [7, 8, 9]\n",
    "])\n",
    "y = np.array([\n",
    "              1, 2, 3\n",
    "])\n",
    "\n",
    "# Проверим shape первого батча\n",
    "iterator = batch_generator(X, y, 2)\n",
    "X_batch, y_batch = next(iterator)\n",
    "assert X_batch.shape == (2, 3), y_batch.shape == (2,)\n",
    "assert np.allclose(X_batch, X[:2]), np.allclose(y_batch, y[:2])\n",
    "\n",
    "# Проверим shape последнего батча (их всего два)\n",
    "X_batch, y_batch = next(iterator)\n",
    "assert X_batch.shape == (1, 3), y_batch.shape == (1,)\n",
    "assert np.allclose(X_batch, X[2:]), np.allclose(y_batch, y[2:])\n",
    "\n",
    "# Проверим, что итерации закончились\n",
    "iter_ended = False\n",
    "try:\n",
    "    next(iterator)\n",
    "except StopIteration:\n",
    "    iter_ended = True\n",
    "assert iter_ended\n",
    "\n",
    "# Еще раз проверим то, сколько батчей создает итератор\n",
    "X = np.random.randint(0, 100, size=(1000, 100))\n",
    "y = np.random.randint(-1, 1, size=(1000, 1))\n",
    "num_iter = 0\n",
    "for _ in batch_generator(X, y, 3):\n",
    "    num_iter += 1\n",
    "assert num_iter == (1000 // 3 + 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 id=\"Задание-2.-Обучите-модель-для-классификации-звезд\">Задание 2. Обучите модель для классификации звезд<a class=\"anchor-link\" href=\"#Задание-2.-Обучите-модель-для-классификации-звезд\">¶</a></h1><p>Загрузите датасет из файла sky_data.csv, разделите его на train/test и обучите на нем нейронную сеть (архитектура ниже). Обучайте на батчах с помощью оптимизатора Adam, lr подберите сами, пробуйте что-то вроде 1e-2</p>\n",
    "<p>Архитектура:</p>\n",
    "<ol>\n",
    "<li>Dense Layer с relu активацией и 50 нейронами</li>\n",
    "<li>Dropout 80% (если другой keep rate дает сходимость лучше, то можно изменить) (попробуйте 50%) </li>\n",
    "<li>BatchNorm</li>\n",
    "<li>Dense Layer с relu активацией и 100 нейронами</li>\n",
    "<li>Dropout 80% (если другой keep rate дает сходимость лучше, то можно изменить) (попробуйте для разнообразия 50%)</li>\n",
    "<li>BatchNorm</li>\n",
    "<li>Выходной Dense слой c количеством нейронов, равному количеству классов</li>\n",
    "</ol>\n",
    "<p>Лосс - CrossEntropy.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>В датасете классы представлены строками, поэтому классы нужно закодировать. Для этого в строчке ниже объявлен dict, с помощью него и функции map превратите столбец с таргетом в целое число. Кроме того, за вас мы выделили признаки, которые нужно использовать.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Загрузка-и-обработка-данных\">Загрузка и обработка данных<a class=\"anchor-link\" href=\"#Загрузка-и-обработка-данных\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['ra', 'dec', 'u', 'g', 'r', 'i', 'z', 'run', 'camcol', 'field']\n",
    "target_column = 'class'\n",
    "\n",
    "target_mapping = {\n",
    "    'GALAXY': 0,\n",
    "    'STAR': 1,\n",
    "    'QSO': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GALAXY    4998\n",
       "STAR      4152\n",
       "QSO        850\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('https://drive.google.com/uc?id=1K-8CtATw6Sv7k2dXco1fL5MAhTbKtIH3')\n",
    "data['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>objid</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>u</th>\n",
       "      <th>g</th>\n",
       "      <th>r</th>\n",
       "      <th>i</th>\n",
       "      <th>z</th>\n",
       "      <th>run</th>\n",
       "      <th>rerun</th>\n",
       "      <th>camcol</th>\n",
       "      <th>field</th>\n",
       "      <th>specobjid</th>\n",
       "      <th>class</th>\n",
       "      <th>redshift</th>\n",
       "      <th>plate</th>\n",
       "      <th>mjd</th>\n",
       "      <th>fiberid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.237650e+18</td>\n",
       "      <td>183.531326</td>\n",
       "      <td>0.089693</td>\n",
       "      <td>19.47406</td>\n",
       "      <td>17.04240</td>\n",
       "      <td>15.94699</td>\n",
       "      <td>15.50342</td>\n",
       "      <td>15.22531</td>\n",
       "      <td>752</td>\n",
       "      <td>301</td>\n",
       "      <td>4</td>\n",
       "      <td>267</td>\n",
       "      <td>3.722360e+18</td>\n",
       "      <td>STAR</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>3306</td>\n",
       "      <td>54922</td>\n",
       "      <td>491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.237650e+18</td>\n",
       "      <td>183.598371</td>\n",
       "      <td>0.135285</td>\n",
       "      <td>18.66280</td>\n",
       "      <td>17.21449</td>\n",
       "      <td>16.67637</td>\n",
       "      <td>16.48922</td>\n",
       "      <td>16.39150</td>\n",
       "      <td>752</td>\n",
       "      <td>301</td>\n",
       "      <td>4</td>\n",
       "      <td>267</td>\n",
       "      <td>3.638140e+17</td>\n",
       "      <td>STAR</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>323</td>\n",
       "      <td>51615</td>\n",
       "      <td>541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.237650e+18</td>\n",
       "      <td>183.680207</td>\n",
       "      <td>0.126185</td>\n",
       "      <td>19.38298</td>\n",
       "      <td>18.19169</td>\n",
       "      <td>17.47428</td>\n",
       "      <td>17.08732</td>\n",
       "      <td>16.80125</td>\n",
       "      <td>752</td>\n",
       "      <td>301</td>\n",
       "      <td>4</td>\n",
       "      <td>268</td>\n",
       "      <td>3.232740e+17</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.123111</td>\n",
       "      <td>287</td>\n",
       "      <td>52023</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.237650e+18</td>\n",
       "      <td>183.870529</td>\n",
       "      <td>0.049911</td>\n",
       "      <td>17.76536</td>\n",
       "      <td>16.60272</td>\n",
       "      <td>16.16116</td>\n",
       "      <td>15.98233</td>\n",
       "      <td>15.90438</td>\n",
       "      <td>752</td>\n",
       "      <td>301</td>\n",
       "      <td>4</td>\n",
       "      <td>269</td>\n",
       "      <td>3.722370e+18</td>\n",
       "      <td>STAR</td>\n",
       "      <td>-0.000111</td>\n",
       "      <td>3306</td>\n",
       "      <td>54922</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.237650e+18</td>\n",
       "      <td>183.883288</td>\n",
       "      <td>0.102557</td>\n",
       "      <td>17.55025</td>\n",
       "      <td>16.26342</td>\n",
       "      <td>16.43869</td>\n",
       "      <td>16.55492</td>\n",
       "      <td>16.61326</td>\n",
       "      <td>752</td>\n",
       "      <td>301</td>\n",
       "      <td>4</td>\n",
       "      <td>269</td>\n",
       "      <td>3.722370e+18</td>\n",
       "      <td>STAR</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>3306</td>\n",
       "      <td>54922</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          objid          ra       dec         u         g         r         i  \\\n",
       "0  1.237650e+18  183.531326  0.089693  19.47406  17.04240  15.94699  15.50342   \n",
       "1  1.237650e+18  183.598371  0.135285  18.66280  17.21449  16.67637  16.48922   \n",
       "2  1.237650e+18  183.680207  0.126185  19.38298  18.19169  17.47428  17.08732   \n",
       "3  1.237650e+18  183.870529  0.049911  17.76536  16.60272  16.16116  15.98233   \n",
       "4  1.237650e+18  183.883288  0.102557  17.55025  16.26342  16.43869  16.55492   \n",
       "\n",
       "          z  run  rerun  camcol  field     specobjid   class  redshift  plate  \\\n",
       "0  15.22531  752    301       4    267  3.722360e+18    STAR -0.000009   3306   \n",
       "1  16.39150  752    301       4    267  3.638140e+17    STAR -0.000055    323   \n",
       "2  16.80125  752    301       4    268  3.232740e+17  GALAXY  0.123111    287   \n",
       "3  15.90438  752    301       4    269  3.722370e+18    STAR -0.000111   3306   \n",
       "4  16.61326  752    301       4    269  3.722370e+18    STAR  0.000590   3306   \n",
       "\n",
       "     mjd  fiberid  \n",
       "0  54922      491  \n",
       "1  51615      541  \n",
       "2  52023      513  \n",
       "3  54922      510  \n",
       "4  54922      512  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Features\n",
    "X = data[feature_columns]\n",
    "# Extract target\n",
    "y = data[target_column]\n",
    "\n",
    "# encode target with target_mapping\n",
    "y = y.map(target_mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Нормализация фичей</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Просто вычтите среднее и поделитe на стандартное отклонение (с помощью пандас). Также преобразуйте всё в np.array\n",
    "X = np.array((X - X.mean()) / X.std())\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert type(X) == np.ndarray and type(y) == np.ndarray, 'Проверьте, что получившиеся массивы являются np.ndarray'\n",
    "assert np.allclose(y[:5], [1,1,0,1,1])\n",
    "assert X.shape == (10000, 10)\n",
    "assert np.allclose(X.mean(axis=0), np.zeros(10)) and np.allclose(X.std(axis=0), np.ones(10)), 'Данные не отнормированы'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Обучение</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "# Превратим данные в тензоры, чтобы потом было удобнее\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_test = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Хорошо, данные мы подготовили, теперь надо объявить модель</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Архитектура:</p>\n",
    "<ol>\n",
    "<li>Dense Layer с relu активацией и 50 нейронами</li>\n",
    "<li>Dropout 80% (если другой keep rate дает сходимость лучше, то можно изменить) (попробуйте 50%) </li>\n",
    "<li>BatchNorm</li>\n",
    "<li>Dense Layer с relu активацией и 100 нейронами</li>\n",
    "<li>Dropout 80% (если другой keep rate дает сходимость лучше, то можно изменить) (попробуйте для разнообразия 50%)</li>\n",
    "<li>BatchNorm</li>\n",
    "<li>Выходной Dense слой c количеством нейронов, равному количеству классов</li>\n",
    "</ol>\n",
    "<p>Лосс - CrossEntropy.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_model(dropout_p=0.5, model_lr=1e-3):\n",
    "    torch.manual_seed(42) \n",
    "    np.random.seed(42)\n",
    "    model = nn.Sequential(\n",
    "\n",
    "        nn.Linear(in_features=X_train.shape[1], out_features=50), \n",
    "        nn.ReLU(), \n",
    "        nn.Dropout(p=dropout_p), \n",
    "        nn.BatchNorm1d(num_features=50), \n",
    "\n",
    "        nn.Linear(in_features=50, out_features=100), \n",
    "        nn.ReLU(), \n",
    "        nn.Dropout(p=dropout_p), \n",
    "        nn.BatchNorm1d(num_features=100), \n",
    "\n",
    "        nn.Linear(in_features=100, out_features=len(y_train.unique()))\n",
    "\n",
    "    )\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=model_lr)\n",
    "    \n",
    "    return model, optimizer, loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optimizer, loss_fn = new_model(dropout_p=0.8, model_lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Обучающий-цикл\">Обучающий цикл<a class=\"anchor-link\" href=\"#Обучающий-цикл\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, y_train, X_test, y_test, num_epoch):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    for i in range(num_epoch):\n",
    "        epoch_train_losses = []\n",
    "        for X_batch, y_batch in batch_generator(X_train, y_train, 500):\n",
    "            # На лекции мы рассказывали, что дропаут работает по-разному во время обучения и реального предсказания\n",
    "            # Чтобы это учесть нам нужно включать и выключать режим обучения, делается это командой ниже\n",
    "            model.train()\n",
    "            # Посчитаем предсказание и лосс\n",
    "            preds = model.forward(X_batch)\n",
    "            loss = loss_fn(preds, y_batch)\n",
    "            \n",
    "            # зануляем градиент\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # backward\n",
    "            loss.backward()\n",
    "            \n",
    "            # ОБНОВЛЯЕМ веса\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Запишем число (не тензор) в наши батчевые лоссы\n",
    "            epoch_train_losses.append(loss.item())        \n",
    "        train_losses.append(np.mean(epoch_train_losses))\n",
    "        \n",
    "        # Теперь посчитаем лосс на тесте\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # Сюда опять же надо положить именно число равное лоссу на всем тест датасете\n",
    "            test_losses.append(loss_fn(model.forward(X_test), y_test))\n",
    "        \n",
    "        if i % 3 == 0:\n",
    "            print(f\"epoch #{i} | test_loss: {test_losses[-1]}\")\n",
    "            \n",
    "    return train_losses, test_losses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_loss_decreased():\n",
    "    print(\"На графике сверху, точно есть сходимость? Точно-точно? [Да/Нет]\")\n",
    "    s = input()\n",
    "    if s.lower() == 'да':\n",
    "        print(\"Хорошо!\")\n",
    "    else:\n",
    "        raise RuntimeError(\"Можно уменьшить дропаут, уменьшить lr, поправить архитектуру, etc\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #0 | test_loss: 0.21853764355182648\n",
      "epoch #3 | test_loss: 0.22022123634815216\n",
      "epoch #6 | test_loss: 0.21809619665145874\n",
      "epoch #9 | test_loss: 0.2188233584165573\n",
      "epoch #12 | test_loss: 0.21639755368232727\n",
      "epoch #15 | test_loss: 0.21823352575302124\n",
      "epoch #18 | test_loss: 0.21321633458137512\n",
      "epoch #21 | test_loss: 0.21127808094024658\n",
      "epoch #24 | test_loss: 0.2116299867630005\n",
      "epoch #27 | test_loss: 0.2109084278345108\n",
      "epoch #30 | test_loss: 0.21463601291179657\n",
      "epoch #33 | test_loss: 0.2121107131242752\n",
      "epoch #36 | test_loss: 0.21358932554721832\n",
      "epoch #39 | test_loss: 0.2106352597475052\n",
      "epoch #42 | test_loss: 0.21043530106544495\n",
      "epoch #45 | test_loss: 0.21086174249649048\n",
      "epoch #48 | test_loss: 0.21171125769615173\n",
      "epoch #51 | test_loss: 0.21177424490451813\n",
      "epoch #54 | test_loss: 0.20845727622509003\n",
      "epoch #57 | test_loss: 0.20926439762115479\n",
      "epoch #60 | test_loss: 0.2101113498210907\n",
      "epoch #63 | test_loss: 0.20697958767414093\n",
      "epoch #66 | test_loss: 0.2062680423259735\n",
      "epoch #69 | test_loss: 0.20332683622837067\n",
      "epoch #72 | test_loss: 0.20358112454414368\n",
      "epoch #75 | test_loss: 0.2085142582654953\n",
      "epoch #78 | test_loss: 0.19944104552268982\n",
      "epoch #81 | test_loss: 0.19986623525619507\n",
      "epoch #84 | test_loss: 0.2047751545906067\n",
      "epoch #87 | test_loss: 0.2004082053899765\n",
      "epoch #90 | test_loss: 0.19997638463974\n",
      "epoch #93 | test_loss: 0.20367199182510376\n",
      "epoch #96 | test_loss: 0.19982118904590607\n",
      "epoch #99 | test_loss: 0.20290492475032806\n",
      "epoch #102 | test_loss: 0.19641299545764923\n",
      "epoch #105 | test_loss: 0.199258953332901\n",
      "epoch #108 | test_loss: 0.20009218156337738\n",
      "epoch #111 | test_loss: 0.1992546170949936\n",
      "epoch #114 | test_loss: 0.20037081837654114\n",
      "epoch #117 | test_loss: 0.19841913878917694\n",
      "epoch #120 | test_loss: 0.19702762365341187\n",
      "epoch #123 | test_loss: 0.19721576571464539\n",
      "epoch #126 | test_loss: 0.19684024155139923\n",
      "epoch #129 | test_loss: 0.19788311421871185\n",
      "epoch #132 | test_loss: 0.19520442187786102\n",
      "epoch #135 | test_loss: 0.19849123060703278\n",
      "epoch #138 | test_loss: 0.19632534682750702\n",
      "epoch #141 | test_loss: 0.1941223442554474\n",
      "epoch #144 | test_loss: 0.19416062533855438\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-11a727328cc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-122-6c23c29c384a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(X_train, y_train, X_test, y_test, num_epoch)\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;31m# Посчитаем предсказание и лосс\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1668\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   1669\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1670\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1671\u001b[0m     )\n\u001b[1;32m   1672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses, test_losses = train(X_train, y_train, X_test, y_test, 1000)\n",
    "plt.plot(range(len(train_losses)), train_losses, label='train')\n",
    "plt.plot(range(len(test_losses)), test_losses, label='test')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "    \n",
    "check_loss_decreased()\n",
    "assert train_losses[-1] < 0.3 and test_losses[-1] < 0.3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Вычислите-accuracy-получившейся-модели-на-train-и-test\">Вычислите accuracy получившейся модели на train и test<a class=\"anchor-link\" href=\"#Вычислите-accuracy-получившейся-модели-на-train-и-test\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model.eval()\n",
    "train_pred_labels = #YOUR CODE: use forward\n",
    "test_pred_labels = #YOUR CODE: use forward\n",
    "\n",
    "train_acc = accuracy_score(# YOUR CODE)\n",
    "test_acc = accuracy_score(# YOUR CODE)\n",
    "\n",
    "assert train_acc > 0.9, \"Если уж классифицировать звезды, которые уже видел, то не хуже, чем в 90% случаев\"\n",
    "assert test_acc > 0.9, \"Новые звезды тоже надо классифицировать хотя бы в 90% случаев\"\n",
    "\n",
    "print(\"Train accuracy: {}\\nTest accuracy: {}\".format(train_acc, test_acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 id=\"Задание-3.-Исправление-ошибок-в-архитектуре\">Задание 3. Исправление ошибок в архитектуре<a class=\"anchor-link\" href=\"#Задание-3.-Исправление-ошибок-в-архитектуре\">¶</a></h1><p>Только что вы обучили полносвязную нейронную сеть. Теперь вам предстоит проанализировать архитектуру нейронной сети ниже, исправить в ней ошибки и  обучить её с помощью той же функции train. Пример исправления ошибок есть в семинаре Григория Лелейтнера.</p>\n",
    "<p>Будьте осторожнее и убедитесь, что перед запуском train вы вновь переопределили все необходимые внешние переменные (train обращается к глобальным переменным, в целом так делать не стоит, но сейчас это было оправдано, так как иначе нам пришлось бы передавать порядка 7-8 аргументов).</p>\n",
    "<p>Чтобы у вас получилась такая же архитектура, как у нас, и ответы совпали, давайте определим некоторые правила, как исправлять ошибки:</p>\n",
    "<ol>\n",
    "<li>Если вы видите лишний нелинейный слой, который стоит не на своем месте, просто удалите его. (не нужно добавлять новые слои, чтобы сделать постановку изначального слоя разумной. Удалять надо самый последний слой, который все портит. Для линейных слоев надо что-то исправить, а не удалить его)</li>\n",
    "<li>Если у слоя нет активации, то добавьте ReLU или другую подходящую активацию</li>\n",
    "<li>Если что-то не так с learning_rate, то поставьте 1e-2</li>\n",
    "<li>Если что-то не так с параметрами, считайте первый параметр, который появляется, как верный (т.е. далее в сети должен использоваться он).</li>\n",
    "<li>Ошибки могут быть и в полносвязных слоях. </li>\n",
    "<li>Любые другие проблемы решаются более менее однозначно, если же у вас есть серьезные сомнения, то напишите в беседу в телеграме и пинганите меня @AlexPak</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Задача все та же - классификация небесных объектов на том же датасете. После исправления сети вам нужно обучить ее.</p>\n",
    "<p><strong>Ответ на задачу - средний лосс на тестовом датасете</strong></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.manual_seed(42)   \n",
    "np.random.seed(42)\n",
    "# WRONG ARCH\n",
    "model = nn.Sequential(\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(6, 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(100, 200),\n",
    "    nn.Softmax(),\n",
    "    nn.Linear(200, 200),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(200, 3),\n",
    "    nn.Dropout(p=0.5)\n",
    ")\n",
    "\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters[:-2], lr=1e-100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# RIGHT ARCH\n",
    "torch.manual_seed(42)   \n",
    "np.random.seed(42)\n",
    "model = nn.Sequential(\n",
    "    <YOUR CODE>\n",
    ")\n",
    "\n",
    "\n",
    "loss_fn = <YOUR CODE>\n",
    "optimizer = <YOUR CODE>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"Обучите-и-протестируйте-модель-так-же,-как-вы-это-сделали-в-задаче-2.-Вычислите-accuracy.\">Обучите и протестируйте модель так же, как вы это сделали в задаче 2. Вычислите accuracy.<a class=\"anchor-link\" href=\"#Обучите-и-протестируйте-модель-так-же,-как-вы-это-сделали-в-задаче-2.-Вычислите-accuracy.\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#YOUR CODE\n",
    "\n",
    "train_acc = <YOUR CODE>\n",
    "test_acc = <YOUR CODE>\n",
    "\n",
    "\n",
    "assert train_acc > 0.9, \"Если уж классифицировать звезды, которые уже видел, то не хуже, чем в 90% случаев\"\n",
    "assert test_acc > 0.9, \"Новые звезды тоже надо классифицировать хотя бы в 90% случаев\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"Задание-4.-Сделайте-выводы\">Задание 4. Сделайте выводы<a class=\"anchor-link\" href=\"#Задание-4.-Сделайте-выводы\">¶</a></h2><p>Начиная с какого количества блоков минимальный лосс за время обучения увеличивается? Почему лишнее количество блоков не помогает модели?</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
